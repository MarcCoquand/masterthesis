\chapter{Method}

To evaluate if the functional approach to creating servers is more maintainable
than existing solutions, a comparative study will be done. A popular library
for developing server applications is by using an unopiniated solution using
Express, which is a good candidate to compare to Cause. Express is an
unopiniated server framework written for Node.js for Javascript.  That a
framework is unopiniated means that it does not force you to architecture your
code in any specific way.  

An idiomatic server both made in Cause and the popular framework
for Node Express. They will feature similar functionality which is a library api
with the endpoints:

\begin{itemize}
    \item \texttt{GET ``api/books?released=int\&author=string''} Get a list of
    books and optionally ask for a specific author or a book from a specific
    year
    \item \texttt{DELETE ``api/books/:id''} Delete a book with a specified ID.
    \item \texttt{POST ``api/books/:id'' OR ``api/books/''} Create a new book or
    override a specific book
\end{itemize}

The server will also make use of a hashmap for database connection.

The accepted content types will be \texttt{application/json} and
\texttt{www-url-formencoded} for all endpoints and the displayable content-types
are \texttt{text/plain} and \texttt{application/json}. Both implementations will handle
all of the error cases. They will also be written in an idiomatic way, that is
they will not take the challenges outlined in Chapter~\ref{background} into
consideration; the only requirement is that they compile.

The two solutions are in the appendix, with the ReasonML implementation in
section~\ref{reasonmlrest} and the Node solution in section~\ref{nodejsrest}.

\section{Evaluating maintainability}

The aspects that to be evaluated when measuring maintainability were discussed
in Chapter~\ref{background}. To recap the important aspects were:

\begin{itemize}
    \item Testability
    \item Extendability
    \item Readability
    \item Error-proneness
\end{itemize}

Chapter~\ref{background} established that the SOLID principles can be used to
as guidelines for creating maintainable software. Those principles will
therefore be used as criteria that Cause should be evaulated against.  However
these guidelines do not state anything about the readability of the software.
Thus two different methods will be used to measure readability and to measure
the testability, extendability and error-proneness.


\section{SOLID principles in Functional programming}\label{dependencyinjection}

To evaluate the testability, error-proneness and extendability  Deductive
reasoning can be used to find if the solution follows each criteria.  The SOLID
guidelines were however written for Object-oriented programming and thus we define 
a new definition for SOLID Functional programming, based on the object-oriented
principles.

\subsection{Single Responsibility Principle}

A function takes a single input and produces a single output. If file structure
is centered around the morphisms of a single type then the responsibility of a
file is to morph that type into some other value. Thus it keeps the modules
focused and simple and would ensure that the single responsibility principle is
held. It can also be thought of as ``One function modifies one thing''. So in
summary, a program follows the Single Responsibility Principle if 

\begin{enumerate}
    \item Each functions performs only a morphism, which is guaranteed if the function
        is pure.
	\item The file does not contain functions that do not contain any of the
types declared within that file. However, this rule has an exception for
functions that are only used by the other functions within that module ( called
a helper function). Helper functions can be merged into the function that uses
it but we choose to split them up for readability purposes.
\end{enumerate}

\subsection{Liskov Substitution Principle}

Liskov's Substitution Principle states how reasoning about subtyping among
objects should be done. If S is a subtype of T, then the subtype relation mean
that any term S can be safely used in a context where type T is expected. Since
subtypes do not exist in classic functional programming some translation is
needed. The formal requirements of Liskov's Substitution Principle are as
follows:

\begin{itemize}
    \item Contravariance of method arguments should be in the subtype.
    \item Covariance of method arguments in the subtype.
    \item No new exceptions should be thrown by each subtype, except where
        those exceptions are themselves subtypes of exceptions thrown by the
        supertype.
\end{itemize}

In functional programming, Liskov Substitution Principle is simply
Contravariant Functors.  In order to comply with the principle, argument types
overriding a method must be contravariant and the reverse should be true for
the return type, it should be covariant.  A contravariant type can only be
overridden by using $contramap$. And it's result is naturally in positive
position hence it's covariant.

\subsection{Dependency Inversion Principle} 

Dependency Inversion Principle states that the logic should not depend on it's
environment. To achieve that in functional programming the environment can
be abstracted and taken as parameters of the program. For instance given the
program readNPrint in Figure~\ref{diexample}, this program depends on the
computer IO, making it difficult to extend it to different environments, such as
databases. 

\begin{figure}[H]
    \begin{lstlisting}
readNPrint : IO () 
readNPrint = readLine >>= putStrLn
    \end{lstlisting}
    \caption{A program that reads input from the computer and then prints it.}
    \label{diexample}
\end{figure}

Instead, Figure~\ref{withdiexample} shows how the parameters are abstracted and
readNPrint is a higher order function instead that takes some function that
can generate a string and some function that can print a string.


\begin{figure}[H]
    \begin{lstlisting}
readNPrint : (IO String) -> (String -> IO ()) -> IO ()
readNPrint reader printer = reader >>= printer

-- and then later
consoleIO : IO ()
consoleIO = readNPrint readLine putStrLn
    \end{lstlisting}
    \caption{A program that reads input from the computer and then prints it,
    where the logic is separated from it's environment.}
    \label{withdiexample}
\end{figure}

This way, the dependencies can be mocked and replaced with different ones. So if
we later want to create a $applicationIO$ we can reuse $readNPrint$ with the
functions for printing in the application and reading input from the
application.

Now for a REST api library, it means that the logic should not depend on it's
environment means that the specification of the REST api should not depend on
the server implementation. In other words, it should be trivial to port the
server logic to another runtime if needed. To do this, GADTs can be used to
separate the expression from it's evaluation. So the REST api is simply
described as instructions of a GADT. 

\subsection{Interface Segregation Principle} 

Interface Segragation Principle states that no client should be forced to depend
on methods it does not use. This translates to, in Functional
programming, that the smallest set of data should be used for each function to
work. Recall earlier that types can be thought of as sets. Recall also that the
cardinality of a set is the amount of possible values that set can have. If the
cardinality of a type is higher than expected it allows introducing illegal
states. For example, $type\ Color = Blue | Green | Red$ has a cardinality of 3
(since it can either be Blue, Green or Red) whereas Fig.~\ref{colorcardinality}
has a cardinality of $2\cdot 2\cdot 2 = 8$ meaning that it has 5 states that are
impossible! By choosing the right data structure it lowers the amount of
possible values that are possible. So Interface Segragation Principle in
Functional programming states that a function should not be able to produce
values it does not use.

\begin{figure}[H]
    \begin{lstlisting}
type Color = { Blue: Bool, Red: Bool, Green: Bool}
    \end{lstlisting}
    \caption{Product type Color with cardinality too high}
    \label{colorcardinality}
\end{figure}

Observe that in Fig~\ref{twomanyoperations}, the type \texttt{IUserRepo} has two
operations, one which is not needed by the \texttt{getUserEndpoint} (why would 
that function need to storeUser?). Thus the function is capable of having more 
values than it should be. This means it breaks the Interface segregation principle.

\begin{figure}[H]
    \begin{lstlisting}
data IUserRepo =  {
	getUser : Id -> IO User,
	storeUser : User -> Id -> IO ()
}

-- Later on
getUserEndpoint : IUserRepo -> Request -> Response
-- ...
    \end{lstlisting}
    \caption{Normal interface for operations}
    \label{twomanyoperations}
\end{figure}

So in summary, adherence to interface segregation principle means that the
cardinality of the types are minimized.

\subsection{Open/Closed principles}

Open/Closed principle states that software entities (classes, modules,
functions, etc.) should be open for extension, but closed for modification.

The OCP is an advice on how to write modules in such a way that we have
backwards compatibility and so that if extra functionality is needed, the
modifier does not need to look at the class in order to make modifications. So
if a class has some new requirements you do not need to modify the source code
but can instead extend the superclass.

When this principle is applied into Functional programming, we run into the
expression problem. The expression problem states that \textit{``The goal is to
define a datatype by cases, where one can add new cases to the datatype and new
functions over the datatype, without recompiling existing code and while
retaining static type safety (e.g., no casts).''}

(ADD\_REFERENCE \url{http://homepages.inf.ed.ac.uk/wadler/papers/expression/expression.txt})

The similarity with expression problem and OCP is that you want to be able to
extend the program (add new cases to the datatype) without recompiling existing
code.  Object-oriented programming uses classes that should be open for
extension and closed for modification. In functional programming, when this
principle is applied, new cases to datatype should be possible and new
functions.  OCP exists because modifying battle tested code is dangerous and
might cause regressions. Thus a preferable solution is to extend the previous
code instead.

\subsubsection{Example: Creating a OCP compliant paint programming}

In a paint program, various shapes should be possible to paint: circles,
squares, stars and custom shapes. It should also have a custom menu depending on
the shape, a circle should be able to set the radius, a square the area and
stars the diameter.

A functional approach is to create a sum type of the shape, seen in
Fig~\ref{sumtypeshapes}.  To add more shapes, the original source code would
need to be modified.  This means that Open/Closed principle is not being
followed. It can cause a lot of trouble down the line, one function is
acceptable but what if we had thousands of functions that depended on shape.
Adding one shape would mean changing thousands of lines of code scattered all
over the place.

\begin{figure}[H]
    \begin{lstlisting}
type Shape 
  = Star size
  | Custom [vector]
  | Circle radius curvature
  | Square size

render : Shape -> IO ()
render shape =
	case shape of
		Star size = Star.render(size)
		...

-- Do the same thing
renderMenu : Shape -> IO ()
renderMenu = ...
    \end{lstlisting}
    \caption{A sum type of shapes}
    \label{sumtypeshapes}
\end{figure}

A different approach is by using type classes and contravariance.  In order to
render shapes, there needs some general format which we can use to render them.
Let's assume we have some function $render : Set\ Vector \rightarrow IO\ ()$ for
rendering. This is great because we know that any shape can be represented as a
set of vectors in the end. Let us define $type\ Renderable\ a = Renderable\ (a \rightarrow
Set\ Vector)$. Now it becomes possible to define a render function $render :
Renderable\ a \rightarrow a \rightarrow IO\ ()$, that works for all shapes.  Shapes can be made in
separation now by contramapping properties, seen in fig~\ref{contracircle}.

\begin{figure}[H]
    \begin{lstlisting}
type Renderable a = Renderable (a -> Set Vector)
instance Contravariant a => Renderable a where
	contramap cf b = \a -> b $ cf a

type Circle = {radius: Int}
circle : Renderable Circle
circle = circleToVector . radius -- circleToVector turns it to vector

setRadiusFactor :  Int -> Renderable Circle -> Renderable Circle
setRadiusFactor factor = contramap ({radius = factor})

type Custom = {scale : Int, shape : Set Vector}
custom : Renderable Custom
custom = scale * shape

addVertex : Vector -> Renderable Custom -> Renderable Custom
addVertex vertex = contramap (Set.union vertex)
    \end{lstlisting}
    \caption{A contravariant approach to shapes}
    \label{contracircle}
\end{figure}

Contravariance forces adherence to a certain interface but leaves it open to
extension, in spirit to the Open/Closed Principle. A separate part of the
code can contain Renderable Square, Renderable Star without modifying the
original code. Thus, in Functional programming, contravariance and type classes
can enable OCP compliant code that solves the expression problem. 
So OCP compliant code is code that does not run into the expression problem.

\subsection{Evaluating readability through code reviews}

Code reviews, also known as peer reviews, is an activity where a human evaluates
the program to check for defects, finding better solutions and find readability
aspects. 

To measure the readability of the REST library, a semi-structured code review is
conducted on five different people with varying knowledge of REST apis and
functional programming.

\subsubsection{Semi-structured interviews}

Semi-structured interviews diverges from a structured interview which has a set
amount of questions. In a semi-structured interview the interview is open and
allows for new ideas to enter the discussion. 

Semi-structured interviews are used to gather focused qualitative data. It is
useful for finding specific insights in regards to the readability of the code
and provides insights as to the code can actually be understood by the general
user.

To conduct an semi-structured interview, the interview should avoid leading
questions and use open-ended questions to get descriptive answers rather than
yes or no answers. 

The questions that will be asked are presented below.

\begin{description}
    \item[Q1] What is your experience with RESTful APIs?
    \item[Q2] What is your experience with Express?
    \item[Q3] What is your experience with ReasonML?
    \item[Q4] After being presented the code api, can you explain what it does?
    \item[Q5] Which media types does the endpoint post accept?
    \item[Q6] What is the uri of DELETE?
    \item[Q7] Which media types representations can the endpoint show?
    \item[Q8] Can you demonstrate how you would extend the api and add a new endpoint
    for a PUT request.
    \item[Q9] Looking at the javascript api, can you explain what it does?
    \item[Q10] Which media types does the endpoint get accept?
    \item[Q11] Which content type and accept does post have?
\end{description}

\subsection{Evaluating the answers}

After performing the interviews conclusions can be made by interpreting the
answers to conclude if the code is readable or not. If the code is readable the
users being interviewed should be able to explain to the author what the code
does.

In order to reduce the bias in the experiments each user will be shown a
different code base first. So the 3 users will be shown the implementation in
ReasonML and 2 users will be shown the implementation in Express. This also
shows gives insights as to the reason the users do not understand the solution.

So in summary, the way each aspect of maintainability will be evaluated in both
solutions by the following:

\begin{description}
    \item [Testability] Evaulated by comparing the number of dependencies that
    need to be mocked. 
    \item [Extendability] Evaluated by comparing to SOLID principles.
    \item [Readability] Evaluated by comparing to SOLID principles.
    \item [Error-proneness] Evaluated by SOLID principles and the interviews
        where we ask to extend the solution with a PUT request.
\end{description}

Afterwards from there a discussion can be had about the strengths and weaknesses
of both solutions and the impacts of maintainability by using functional
programming for developing REST servers.





