\chapter{Background}\label{background}

This chapter will look at how concerns and requirements made impact the
maintainability and testability. It aims to establish what are the current
methods of developing applications and how software engineers today approach
testing. 

\section{Architecture} 

When developing large scale applications, often the requirements are as follows:

\begin{itemize}
    \item There is a team of developers
    \item New team members must get productive quickly
    \item The system must be continuously developed and adapt to new
        requirements
    \item The system needs to be continuously tested
    \item System must be able to adapt to new and emerging frameworks
\end{itemize}

Two different approaches to developing these large scale applications are
microservice and monolithic systems. The monolithic system comprises of one big
``top-down'' architecture that dictates what the program should do. This is
simple to develop using some IDE and deploying simply requires deploying some
files to the runtime. 

As the system starts to grow the large monolithic system becomes harder to
understand as the size doubles. As a result, development typically slows down.
Since there are no boundaries, modularity tends to break down and the IDE
becomes slower over time, making it harder to replace parts as needed. Since
redeploying requires the entire application to be replaced and tests becomes
slower; the developer becomes less productive as a result. Since all code is
written in the same environment introducing new technology becomes harder.

Enter microservices, in a microservice architecture the program comprises of
small entities that each have their own responsibility. There can be one service
for metrics, one that interacts with the database and one that takes care of
frontend. This decomposition allows the developers to easier understand parts of
the system, scale into autonomous teams, IDE becomes faster since codebases are
smaller, faults become easier to understand as they each break in isolation.
Also long-term commitment to one stack becomes less and it becomes easier to
introduce a new stack. 

The issue with microservices is that when scaling the complexity becomes harder
to predict. While testing one system in isolation is easier testing the entire
system with all parts together becomes harder. 

A strategy to test systems is to divide testing into a pyramid with 10\% being
E2E-tests, 30\% being integration tests and the rest being unit tests. E2E-tests
take longer to run due to them making calls to system components like databases
and HTTP requests, integration tests run a bit faster and unit tests run very
quick as they simply test a unit in isolation. 

However, Spotify~\cite{spotifyMicroservice} argue that unit tests provide little
benefit and that systems should mostly consist of integration tests. Thus the
amount of tests should be closer to 10\% E2E-tests, 70\% integration tests and
the rest unit tests.

\subsection{Unit testing}

Unit testing is a testing method where the individual units of code and
operating procedures are tested to see if they are fit for use. A unit is
informally the smallest testable part of the application. To deal with units
dependence one can use method stubs, mock objects and fakes to test in
isolation. The goal of unit testing is to isolate each part of the programs and
ensure that the individual parts are correct. It also allows for easier
refactoring since it ensures that the individual parts still satisfy their part
of the application.

To create effective unit tests it's important that it's easy to mock examples.
This is usually hindered if the code is dependant on some state since previous
states might affect future states.

\subsection{Property-based testing}

Property-based testing tests the properties that a function should fulfill. A
property is some logical condition that a specification defines the function
should fulfill.  Compared to unit testing where the programmer creates the mock
values; property based testing generates values automatically to find a
contradiction. For example a function $reverse\, : \; [a]\, \rightarrow\, [a]$,
which takes a list and reverses it's items, should have the property
$reverse\circ reverse\; x = x$. A unit test would check that $reverse [1,2,3] =
[3,2,1]$; a property-based test would instead generate a list of values randomly
and check it's properties hold.

\subsection{Integration testing}

Whereas unit testing validates that the individual parts work in isolation;
integration tests make sure that the modules work when combined. The purpose is
to expose faults that occurs when the modules interact with each other.

\subsection{Challenges}

\subsubsection{Flakiness}

Tests that result in both passing and failing at the same time are defined as
flaky tests.~\cite{googletests} Google reported that 16\% of their tests have
some sort of flakiness in them and that the rate in which they fix flakiness in
tests is the same as rate of increase in flakiness.

\subsubsection{Readability}

The hypothesis of this thesis is that after designing the system following these
guidelines and writing the code in a testable manner that the code becomes much
harder to understand and more complex. The thesis investigates if the different
language paradigms then end up having vastly different complexity when creating
testable systems.

\section{Complexity and relation to testability}

There exists different metrics for measuring software quality. Lines of Code
(LOC) can be used as a measure in the software to find defects.~\cite{defectloc}
As this study will measure different programming languages and software
paradigms where syntax is vastly different, it follows that using LOC to measure
fault is flawed. Thus, here are some other ways to measure complexity:

\begin{description}

    \item [Cyclomatic Complexity] Described further in Chapter~\ref{theory}

    \item [Halsteads metric] A metric that relates to the difficulty of writing
    or understanding code related to operators and operands.~\cite{bergklaas}

    \item [Chidamber and Kemerer Metrics~\cite{chidamber}] A complexity measure
    for Object-oriented programs. Since this study compares functional to
    object-oriented progams this metric is ill suited as it does not allow for
    comparative analysis.

\end{description}

Berg Van Der Klaas explored Halsteads metric and compared OOP and functional
programming. The study notes that the psychological complexity needs to be taken
into account and noted that the use higher order functions may affect results
for functional programs for the Halstead metric. To measure complexity of
software, a program could instead be measured at a lexical level. No
quantitative measure was found for measuring the linguistic structures of the
program and the comprehension. However a qualitative measure called Cognitive
Dimensions was found will be used instead.  Cognitive Dimensions inspects
fourteen different aspects and they are not always applicable for all projects.
Prior research suggests omitting some which has been taken into account and is
explained further in Chapter~\ref{theory}.~\cite{euguenkiss}

